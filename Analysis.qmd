---
title: "Analysis"
format: html
editor: visual
---

```{r}
library(tidyverse)
```

```{r}
Claims_dat <- read.csv("Insurance claims data.csv")
```

# Data Exploration and Pre-processing

```{r}
colSums(is.na(Claims_dat))
```

No missing values.

```{r}
convertYN <- c(14:18, 28:39)

Claims_dat[, convertYN] <- lapply(Claims_dat[, convertYN], function(x) ifelse(x == "Yes", 1, 0))
```

```{r}
sapply(Claims_dat, class)

to_factor <- c(5, 7:9, 12, 14:19, 22:23, 28:39)
Claims_dat[, to_factor] <- lapply(Claims_dat[, to_factor], factor)

# ncap_rating
# Convert ncap_rating to a factor with all possible levels from 0 to 5
Claims_dat$ncap_rating <- factor(Claims_dat$ncap_rating, levels = 0:5)
```

```{r}
Claims_dat <- Claims_dat |>
  select(-c(policy_id, engine_type, max_torque, max_power)) 
```

```{r}
library(caret)
nzv <- nearZeroVar(Claims_dat, saveMetrics= TRUE)
low_variance_features <- rownames(nzv[nzv$nzv == TRUE, ])

Claims_dat %>%
  select(all_of(low_variance_features), claim_status) %>%
  pivot_longer(cols = all_of(low_variance_features), 
               names_to = "Feature", 
               values_to = "Value") %>%
  group_by(Feature, Value) %>%
  summarise(
    Total_Policies = n(),
    Total_Claims = sum(claim_status),
    Claim_Proportion = round(Total_Claims/Total_Policies, 4),
    .groups = 'drop'
  )
```

There is not much difference in proportion of claims between having parking sensors, power steering and speed alert or not. We then can remove these variables as having these features or not does not affect the likelihood of claims.

```{r}
Claims_dat <- Claims_dat[, !(names(Claims_dat) %in% low_variance_features)]
```

# Subscription Length

```{r}
ggplot(Claims_dat, aes(x = subscription_length)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "blue", size = 1) +
  labs(title = "Enhanced Distribution of Subscription Length",
       x = "Subscription Length", y = "Density") +
  theme_minimal()
```

* Peaks in the distribution at 0, 5 and 10 years. This may indicate common subscription duration where customers either start, renew or cancel policies. Peak at around zero means a new wave of new customers just subscribe the policy.

* The distribution is not uniform, which suggests segmentation in customer subscription.

```{r}
ggplot(Claims_dat, aes(x = as.factor(claim_status), y = subscription_length, fill = as.factor(claim_status))) +
  geom_boxplot() +
  labs(title = "Subscription Length by Claim Status", x = "Claim Status", y = "Subscription Length") +
  scale_fill_discrete(name = "Claim Status")
```

The higher median for `Claim Status = 1` indicates that customers with longer subscription lengths may be more slightly make claims

# Vehicle Age

```{r}
ggplot(Claims_dat, aes(x = vehicle_age)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "blue", size = 1) +
  labs(title = "Enhanced Distribution of Vehicle Age",
       x = "Vehicle Age", y = "Density") +
  theme_minimal()
```

* Strong concentration of vehicles with age around 0-2 years, suggesting most insured vehicles are new.

* Rapid decline after 2 years mark. Older vehicle may be less likely to carry insurance (e.g. reduced in value of vehicles)

* Long tails. There are vehicles with age of 20 years.

```{r}
ggplot(Claims_dat, aes(x = as.factor(claim_status), y = vehicle_age, fill = as.factor(claim_status))) +
  geom_boxplot() +
  labs(title = "Vehicle Age by Claim Status", x = "Claim Status", y = "Vehicle Age") +
  scale_fill_discrete(name = "Claim Status")
```

There are more outliers for older vehicles in `Claim Status = 0`, meaning for this type of insurance, old vehicles tends to do not make claims.

## Customer Age

Younger drivers with older vehicles and vice versa might show different claim behaviours.

Certain groups might prefer newer vehicles, which correlate with claims likelihood.

```{r}
ggplot(Claims_dat, aes(x = customer_age, y = vehicle_age)) +
  geom_point(alpha = 0.6) +
  labs(title = "Interaction of Customer Age and Vehicle Age by Claim Status", x = "Customer Age", y = "Vehicle Age", color = "Claim Status")

```

* There is no clear relationship between customer age and their vehicle age. While most vehicles at around 5-6 years of age are held by all age groups, extremely old vehicles (20 years) are spread across age group (U40, U50, U60).

* All customers for this policy are 35 years old and above, which indicates matured or somewhat old pool of customer. This may be due to some specific age or age-related requirements of the policy.

## Correlation

```{r}
library(corrplot)

# Calculate the correlation matrix (use only numeric columns)
correlation_matrix <- cor(Claims_dat[sapply(Claims_dat, is.numeric)], use = "complete.obs")

# Plot the correlation matrix
corrplot(correlation_matrix, method = "color", type = "upper", tl.col = "black", tl.srt = 45)
```

Notice that the correlations between `claim_status` and other variables are approx. zero, it means there is no linear relationship. However, they can still exhibit non-linear relationship.


To evaluate which model is better, we will use ROC and AUC, to compare between True Positive Rate (Sensitivity) against Precision (True Postives/ (True Positives + False Positives)) (Proportion of positive result that are correctly classified) instead of False Positive Rate (1-Specificity).

This is because in our data, number of Negatives or Non-claim is much larger than Positives or Claim. Also, Precision does not include number of True Negatives in its calculation, and is not affected by the imbalance. 


```{r}
library(gbm)
class_boost <- gbm(claim_status ~ .,
                   data = Claims_dat,
                   distribution = "bernoulli", # binary logistic regression
                   n.trees = 2000,
                   shrinkage = 0.01,
                   interaction.depth = 1,
                   cv.folds = 10)

Jclass <- gbm.perf(class_boost, method = "cv")
Jclass 

class_boost_optimal <- gbm(claim_status ~ .,
                           data = Claims_dat,
                           distribution = "bernoulli",
                           n.trees = Jclass,
                           shrinkage = 0.01,
                           interaction.depth = 1)
```

We use `vip` package to determine the the feature importance, which measures how each variable contributes to the predictive power of the model.

```{r}
library(vip)

vi(class_boost_optimal)
vip(class_boost_optimal)
```

We will use `subscription_length`, `vehicle_age`, `region_code`, `customer_age`, and `model` to as features to predict the claim status, and eliminate the rest.

```{r}
Claims_dat <- Claims_dat |>
  select(c(subscription_length, vehicle_age, region_code, customer_age, model, claim_status))
```


```{r}
library(rsample)
set.seed(2024)

claims_split <- Claims_dat %>% 
  initial_split(prop = 3/4)
claims_train <- training(claims_split)
claims_test <- testing(claims_split)
```

Since number of claims is under-represented compared to number of non-claims, we will use put more weights on value of 1 of `claim_status`. We will use cross-validation to determine how much weights to put on claims (2-10) and use ROC_AUC to choose the optimal weights

## GBM

```{r}
library(gbm)
library(pROC)

weight <- seq(2,10, by = 1)
class_boost <- gbm(claim_status ~ .,
                   data = claims_train,
                   distribution = "bernoulli", # binary logistic regression
                   n.trees = 2000,
                   shrinkage = 0.01,
                   interaction.depth = 1,
                   cv.folds = 10,
                   weight = ifelse(claims_status == 1, weight, 1))

Jclass <- gbm.perf(class_boost, method = "cv")
Jclass 

class_boost_optimal <- gbm(claim_status ~ .,
                           data = claims_train,
                           distribution = "bernoulli",
                           n.trees = Jclass,
                           shrinkage = 0.01,
                           interaction.depth = 1,
                           weight = ifelse(claims_status == 1, weight, 1))
```

```{r}
# Initialize variables to store results
auc_results <- numeric(length(weights_to_test))

for (i in seq_along(weights_to_test)) {
  # Current weight
  weight <- weights_to_test[i]
  
  # Fit GBM model with weights
  class_boost <- gbm(claim_status ~ .,
                     data = claims_train,
                     distribution = "bernoulli", # binary logistic regression
                     n.trees = 2000,
                     shrinkage = 0.01,
                     interaction.depth = 1,
                     cv.folds = 10,
                     weights = ifelse(claim_status == 1, weight, 1))
  
  # Evaluate using cross-validated AUC
  cv_pred <- predict(class_boost, claims_train, n.trees = gbm.perf(class_boost, method = "cv"), type = "response")
  auc_results[i] <- roc(claims_train$claim_status, cv_pred)$auc
}

# Combine results into a data frame
results <- data.frame(weight = weights_to_test, auc = auc_results)
print(results)
```


